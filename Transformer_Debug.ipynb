{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 1.é¢„å¤„ç† requirements/configure/tokenizer/dataloader",
   "id": "becde924577e590c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### 1.1 Requirements & Imports",
   "id": "69bdda97b5451cb4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T08:36:20.292396Z",
     "start_time": "2026-01-16T08:36:20.276526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import time\n",
    "import spacy\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "# HuggingFace tokenizers æ ¸å¿ƒç±»\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer as HFTokenizer\n",
    "## BPE æ¨¡å‹ï¼ˆByte Pair Encodingï¼‰\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers import pre_tokenizers, decoders\n",
    "\n",
    "from collections import Counter, OrderedDict\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ],
   "id": "a1e38e1b07bfa27e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T08:36:22.799808Z",
     "start_time": "2026-01-16T08:36:22.781414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# å›ºå®šéšæœºç§å­ï¼Œä¿è¯ç»“æœå¯å¤ç°\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(1234)"
   ],
   "id": "937814ced44b95ce",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### 1.2 Transformer é…ç½®å‚æ•°",
   "id": "766cdadd10fd0033"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T08:36:26.713127Z",
     "start_time": "2026-01-16T08:36:26.696227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# æ¨¡å‹å‚æ•°\n",
    "batch_size = 128 # è®­ç»ƒæ‰¹æ¬¡ å¥è¯\n",
    "max_len = 256    # å•å¥æœ€å¤§é•¿åº¦\n",
    "##\n",
    "# padding=10\n",
    "\n",
    "d_model = 512    # è¯åµŒå…¥å‘é‡ç»´åº¦\n",
    "n_layers = 6     # encoder/decoderå±‚æ•°é‡\n",
    "n_heads = 8      # æ³¨æ„åŠ›å¤´æ•°ï¼š å‡å¦‚æœ‰è¯åµŒå…¥ç»´åº¦d_model = 512 / n_heads = 8 => å•å¤´å‘é‡ç»´åº¦ 512 / 8 = 64ï¼Œå³QKVç»´åº¦\n",
    "ffn_hidden = 2048 # å‰å‘ä¼ æ’­ç»´åº¦ã€‚ 512 -> 2048 -> 512, é€šå¸¸ä¹Ÿç§°ä½œproj\n",
    "drop_prob = 0.1  # dropoutæå‡é²æ£’æ€§ï¼Œéšæœºå¤±æ´»ä¸€äº›èŠ‚ç‚¹\n",
    "n_hidden = ffn_hidden\n",
    "\n",
    "# optimizer parameter setting\n",
    "init_lr = 1e-5\n",
    "factor = 0.9\n",
    "adam_eps = 5e-9\n",
    "patience = 10\n",
    "warmup = 100\n",
    "epoch = 100\n",
    "clip = 1.0\n",
    "weight_decay = 5e-4\n",
    "inf = float('inf')\n"
   ],
   "id": "4f906f086f0929ec",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### 1.3 Tokenizer è‹±å¾·æ–‡ Tokenizer",
   "id": "6eb895959c683c86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T08:36:40.828910Z",
     "start_time": "2026-01-16T08:36:36.842287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer as HFTokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers import pre_tokenizers, decoders\n",
    "\n",
    "\n",
    "class BBPETokenizerManager:\n",
    "    def __init__(self, vocab_size=10000, min_freq=2):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.min_freq = min_freq\n",
    "        self.special_tokens = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]\n",
    "\n",
    "        self.en_path = \"tokenizer_en_bbpe.json\"\n",
    "        self.de_path = \"tokenizer_de_bbpe.json\"\n",
    "\n",
    "        # åŠ è½½æ•°æ®é›† (æ›¿ä»£ torchtext.datasets.Multi30k)\n",
    "        # bentrevett/multi30k æ˜¯ Multi30k çš„å®˜æ–¹ HF é•œåƒç‰ˆæœ¬\n",
    "        print(\"æ­£åœ¨ä» Hugging Face Hub åŠ è½½ Multi30k æ•°æ®é›†...\")\n",
    "        self.dataset = load_dataset(\"bentrevett/multi30k\")\n",
    "\n",
    "        if os.path.exists(self.en_path) and os.path.exists(self.de_path):\n",
    "            print(f\"æ£€æµ‹åˆ°å·²è®­ç»ƒçš„ BBPE åˆ†è¯å™¨ï¼Œæ­£åœ¨åŠ è½½...\")\n",
    "            self.tokenizer_en = HFTokenizer.from_file(self.en_path)\n",
    "            self.tokenizer_de = HFTokenizer.from_file(self.de_path)\n",
    "        else:\n",
    "            print(f\"å¼€å§‹è®­ç»ƒ BBPE åˆ†è¯å™¨...\")\n",
    "            self.tokenizer_en, self.tokenizer_de = self.train_tokenizers()\n",
    "\n",
    "    def train_tokenizers(self):\n",
    "        # 1. å®šä¹‰æ•°æ®ç”Ÿæˆå™¨ (é€‚é… HF Dataset æ ¼å¼: dict)\n",
    "        def batch_iterator(dataset, lang):\n",
    "            for i in range(0, len(dataset), 1000):\n",
    "                yield dataset[i: i + 1000][lang]\n",
    "\n",
    "        # 2. è®­ç»ƒé€»è¾‘\n",
    "        def train(lang):\n",
    "            tokenizer = HFTokenizer(BPE(unk_token=\"<unk>\"))\n",
    "            tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n",
    "            tokenizer.decoder = decoders.ByteLevel()\n",
    "\n",
    "            trainer = BpeTrainer(\n",
    "                vocab_size=self.vocab_size,\n",
    "                min_frequency=self.min_freq,\n",
    "                special_tokens=self.special_tokens,\n",
    "                initial_alphabet=pre_tokenizers.ByteLevel.alphabet()\n",
    "            )\n",
    "\n",
    "            print(f\"æ­£åœ¨è®­ç»ƒ {lang} BBPE åˆ†è¯å™¨...\")\n",
    "            # ä½¿ç”¨ train æ•°æ®é›†è¿›è¡Œè®­ç»ƒ\n",
    "            tokenizer.train_from_iterator(batch_iterator(self.dataset['train'], lang), trainer=trainer)\n",
    "            return tokenizer\n",
    "\n",
    "        tokenizer_de = train('de')\n",
    "        tokenizer_en = train('en')\n",
    "\n",
    "        tokenizer_de.save(self.de_path)\n",
    "        tokenizer_en.save(self.en_path)\n",
    "        print(\"BBPE åˆ†è¯å™¨è®­ç»ƒå®Œæˆã€‚\")\n",
    "\n",
    "        return tokenizer_en, tokenizer_de\n",
    "\n",
    "    def tokenize_en(self, text):\n",
    "        return self.tokenizer_en.encode(text).tokens\n",
    "\n",
    "    def tokenize_de(self, text):\n",
    "        return self.tokenizer_de.encode(text).tokens\n",
    "\n",
    "    # [New] è·å–åŸå§‹æ•°æ®é›†çš„æ¥å£\n",
    "    def get_dataset(self):\n",
    "        return self.dataset\n",
    "\n",
    "\n",
    "# å®ä¾‹åŒ–\n",
    "tokenizer_manager = BBPETokenizerManager(vocab_size=10000, min_freq=2)\n",
    "raw_dataset = tokenizer_manager.get_dataset()\n"
   ],
   "id": "4a9cc8596828cfd2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨ä» Hugging Face Hub åŠ è½½ Multi30k æ•°æ®é›†...\n",
      "æ£€æµ‹åˆ°å·²è®­ç»ƒçš„ BBPE åˆ†è¯å™¨ï¼Œæ­£åœ¨åŠ è½½...\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### 1.4 Dataset ä¸ DataLoader ç”±äº datasets\n",
    "    åº“è¿”å›çš„æ•°æ®ç»“æ„æ˜¯å­—å…¸ï¼ˆä¾‹å¦‚ {'en': '...', 'de': '...'}ï¼‰ï¼Œæˆ‘ä»¬éœ€è¦è°ƒæ•´ Dataset çš„è¯»å–é€»è¾‘ã€‚"
   ],
   "id": "fb738e0013e782f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T08:37:22.768245Z",
     "start_time": "2026-01-16T08:37:22.743149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "# [New] é€‚é… HF Datasets çš„ PyTorch Dataset\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, tokenizer_mgr, split='train'):\n",
    "        self.data = hf_dataset[split]  # è·å–å¯¹åº” split (train/validation/test)\n",
    "        self.tokenizer_mgr = tokenizer_mgr\n",
    "        self.src_lang = 'de'\n",
    "        self.trg_lang = 'en'\n",
    "\n",
    "        # é¢„å…ˆè·å–ç‰¹æ®Š token çš„ ID\n",
    "        self.sos_id = tokenizer_mgr.tokenizer_en.token_to_id(\"<sos>\")\n",
    "        self.eos_id = tokenizer_mgr.tokenizer_en.token_to_id(\"<eos>\")\n",
    "        # å‡è®¾ä¸¤ä¸ªåˆ†è¯å™¨çš„ç‰¹æ®Š token id æ˜¯ä¸€æ ·çš„ï¼ˆé€šå¸¸æ˜¯çš„ï¼‰ï¼Œå¦‚æœä¸æ”¾å¿ƒå¯ä»¥åˆ†åˆ«è·å–\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. è·å–åŸå§‹æ–‡æœ¬\n",
    "        # HF Dataset item æ ¼å¼: {'de': '...', 'en': '...'}\n",
    "        item = self.data[idx]\n",
    "        src_text = item[self.src_lang]\n",
    "        trg_text = item[self.trg_lang]\n",
    "\n",
    "        # 2. åˆ†è¯å¹¶è½¬ ID (Encoding)\n",
    "        # è¿™é‡Œçš„ encode().ids ç›´æ¥è¿”å›æ•°å­—åˆ—è¡¨ï¼Œä¸éœ€è¦å†æŸ¥ Vocab äº†ï¼\n",
    "        # BPE åˆ†è¯å™¨è‡ªå¸¦ Vocab åŠŸèƒ½\n",
    "        src_ids = self.tokenizer_mgr.tokenizer_de.encode(src_text).ids\n",
    "        trg_ids = self.tokenizer_mgr.tokenizer_en.encode(trg_text).ids\n",
    "\n",
    "        # 3. æ·»åŠ  <sos> å’Œ <eos>\n",
    "        src_tensor = torch.tensor([self.sos_id] + src_ids + [self.eos_id], dtype=torch.long)\n",
    "        trg_tensor = torch.tensor([self.sos_id] + trg_ids + [self.eos_id], dtype=torch.long)\n",
    "\n",
    "        return src_tensor, trg_tensor\n",
    "\n",
    "\n",
    "#(ä¿æŒä¸å˜ï¼Œé€»è¾‘é€šç”¨)\n",
    "def collate_fn(batch):\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "    # è·å– pad_id (ä»åˆ†è¯å™¨ä¸­è·å–)\n",
    "    pad_id = tokenizer_manager.tokenizer_en.token_to_id(\"<pad>\")\n",
    "\n",
    "    src_padded = pad_sequence(src_batch, padding_value=pad_id, batch_first=True)\n",
    "    trg_padded = pad_sequence(trg_batch, padding_value=pad_id, batch_first=True)\n",
    "\n",
    "    return src_padded, trg_padded\n",
    "\n",
    "\n",
    "class StandardDataLoader:\n",
    "    def __init__(self, tokenizer_manager):\n",
    "        self.tm = tokenizer_manager\n",
    "\n",
    "    def make_loaders(self, batch_size, device):\n",
    "        print('æ­£åœ¨åˆ›å»º DataLoader...')\n",
    "        hf_data = self.tm.get_dataset()\n",
    "\n",
    "        # åˆ›å»º Dataset å®ä¾‹\n",
    "        train_ds = TranslationDataset(hf_data, self.tm, 'train')\n",
    "        valid_ds = TranslationDataset(hf_data, self.tm, 'validation')\n",
    "        test_ds = TranslationDataset(hf_data, self.tm, 'test')\n",
    "\n",
    "        # åˆ›å»º DataLoader\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=0)\n",
    "        valid_loader = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=0)\n",
    "        test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=0)\n",
    "\n",
    "        # Wrapper ä¿æŒæ¥å£å…¼å®¹\n",
    "        class BatchWrapper:\n",
    "            def __init__(self, src, trg):\n",
    "                self.src = src.to(device)\n",
    "                self.trg = trg.to(device)\n",
    "\n",
    "        def wrap(loader):\n",
    "            for src, trg in loader:\n",
    "                yield BatchWrapper(src, trg)\n",
    "\n",
    "        return wrap(train_loader), wrap(valid_loader), wrap(test_loader)\n",
    "\n",
    "\n",
    "# è¿è¡ŒåŠ è½½\n",
    "loader_helper = StandardDataLoader(tokenizer_manager)\n",
    "train_iter, valid_iter, test_iter = loader_helper.make_loaders(batch_size=batch_size, device=device)\n"
   ],
   "id": "82ee5e851d4364a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨åˆ›å»º DataLoader...\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T08:37:29.861445Z",
     "start_time": "2026-01-16T08:37:29.820951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# éªŒè¯æ•°æ®\n",
    "print('\\n---- éªŒè¯æ•°æ®åŠ è½½ ----')\n",
    "batch = next(train_iter)\n",
    "print(\"Src Shape:\", batch.src.shape)\n",
    "print(\"Trg Shape:\", batch.trg.shape)\n",
    "print(\"Src Example (IDs):\", batch.src[0])\n",
    "\n",
    "# è·å–è¯è¡¨å¤§å°ä¾›åç»­æ¨¡å‹ä½¿ç”¨\n",
    "enc_voc_size = tokenizer_manager.tokenizer_de.get_vocab_size()\n",
    "dec_voc_size = tokenizer_manager.tokenizer_en.get_vocab_size()\n",
    "print(f\"Encoder Vocab Size: {enc_voc_size}\")\n",
    "print(f\"Decoder Vocab Size: {dec_voc_size}\")"
   ],
   "id": "5738e5c7e93836f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- éªŒè¯æ•°æ®åŠ è½½ ----\n",
      "Src Shape: torch.Size([128, 32])\n",
      "Trg Shape: torch.Size([128, 32])\n",
      "Src Example (IDs): tensor([   1,  271,  400,  912,   15,  286,  277,  969,  354, 4463,  261,  624,\n",
      "         354,  519,   17,    2,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0], device='cuda:0')\n",
      "Encoder Vocab Size: 10000\n",
      "Decoder Vocab Size: 10000\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 2. Transformer æ ¸å¿ƒç»„ä»¶æ„å»º\n",
   "id": "774615f11437b963"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### 2.1 è¯ç¼–ç ä¸ä½ç½®ç¼–ç  (Embedding & PE)\n",
    "        1.TokenEmbedding: è´Ÿè´£ word -> vectorã€‚\n",
    "        2.PositionalEncoding: è´Ÿè´£æ³¨å…¥ä½ç½®ä¿¡æ¯ (sin/cos)ã€‚\n",
    "        3.TransformerEmbedding: æŠŠä¸Šé¢ä¸¤è€…åŠ èµ·æ¥ï¼Œå¹¶åŠ ä¸Š Dropoutã€‚"
   ],
   "id": "368bc7c948a43653"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T08:39:25.099223Z",
     "start_time": "2026-01-16T08:39:25.078593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "# ===================================================================\n",
    "# 2.1.1 Token Embedding (è¯åµŒå…¥å±‚)\n",
    "# ===================================================================\n",
    "class TokenEmbedding(nn.Embedding):\n",
    "    \"\"\"\n",
    "        Standard Token Embedding Layer\n",
    "        ç›®çš„ï¼šå°† 1 ä¸ª token (int) è½¬æˆä¸€ä¸²å‘é‡ (vector)\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size,d_model, padding_idx=None):\n",
    "        super(TokenEmbedding, self).__init__(vocab_size,d_model,padding_idx=padding_idx)\n",
    "\n",
    "# ===================================================================\n",
    "# 2.1.2 Positional Encoding (ä½ç½®ç¼–ç )\n",
    "# ===================================================================\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Positional Encoding Layer\n",
    "    [User Comment] Position ç¼–ç å…¬å¼ ... (1,1,0,1) -> (sin, cos...)\n",
    "    ä½œç”¨ï¼šå› ä¸º Transformer æ˜¯å¹¶è¡Œå¤„ç†çš„ï¼Œæ²¡æœ‰ RNN é‚£æ ·çš„æ—¶åºæ„Ÿï¼Œ\n",
    "    æ‰€ä»¥éœ€è¦äººä¸ºåŠ å…¥ä½ç½®ä¿¡æ¯ã€‚\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_len, device):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        # åˆå§‹åŒ–ä½ç½®ç¼–ç çŸ©é˜µ [max_len, d_model]\n",
    "        self.encoding = torch.zeros(max_len, d_model, device=device)\n",
    "        self.encoding.requires_grad = False  # [Standard] ä½ç½®ç¼–ç æ˜¯å›ºå®šçš„ï¼Œä¸éœ€è¦è®­ç»ƒæ›´æ–°\n",
    "\n",
    "        # ç”Ÿæˆä½ç½®ç´¢å¼• [0, 1, 2, ..., max_len-1] -> [max_len, 1]\n",
    "        pos = torch.arange(0, max_len, device=device).float().unsqueeze(1)\n",
    "\n",
    "        # è®¡ç®—åˆ†æ¯ä¸­çš„ term: 10000^(2i/d_model)\n",
    "        # ä½¿ç”¨ log ç©ºé—´è®¡ç®—æ›´æ•°å€¼ç¨³å®š: exp(2i * -log(10000) / d_model)\n",
    "        _2i = torch.arange(0, d_model, 2, device=device).float()\n",
    "\n",
    "        # [User Comment] æŒ‰ç…§å…¬å¼è®¡ç®—\n",
    "        # PE(pos, 2i) = sin(pos / 10000^(2i/d_model))\n",
    "        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / d_model)))\n",
    "        # PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
    "        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / d_model)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_len] æˆ– [batch_size, seq_len, d_model]\n",
    "        # æˆ‘ä»¬è¿™é‡Œåªéœ€è¦ seq_len\n",
    "        seq_len = x.size(1)\n",
    "\n",
    "        # [Standard] å–å‡ºå¯¹åº”é•¿åº¦çš„ä½ç½®ç¼–ç \n",
    "        # return shape: [seq_len, d_model]\n",
    "        return self.encoding[:seq_len, :]\n",
    "\n",
    "# ===================================================================\n",
    "# 2.1.3 Transformer Embedding (æ•´ä½“å°è£…)\n",
    "# ===================================================================\n",
    "class TransformerEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model,\n",
    "                 max_len,\n",
    "                 drop_prob, device, padding_idx=None):\n",
    "        super(TransformerEmbedding, self).__init__()\n",
    "\n",
    "        # 1. è¯åµŒå…¥\n",
    "        self.tok_emb = TokenEmbedding(vocab_size, d_model, padding_idx=padding_idx)\n",
    "\n",
    "        # 2. ä½ç½®ç¼–ç \n",
    "        self.pos_emb = PositionalEncoding(d_model, max_len, device)\n",
    "\n",
    "        # 3. Dropout\n",
    "        self.drop_out = nn.Dropout(p=drop_prob)\n",
    "\n",
    "        # 4. ç¼©æ”¾å› å­\n",
    "        # è®ºæ–‡ä¸­æåˆ° embedding è¾“å‡ºéœ€è¦ä¹˜ä»¥ sqrt(d_model)ï¼Œè®©æ•°å€¼å˜å¤§ä¸€ç‚¹ï¼Œ\n",
    "        # ä»¥ä¾¿å’Œ positional encoding (èŒƒå›´ -1~1) ç›¸åŠ æ—¶ï¼Œè¯çš„ä¿¡æ¯ä¸ä¼šè¢«æ·¹æ²¡ã€‚\n",
    "        self.scale = math.sqrt(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len]\n",
    "\n",
    "        # step 1: è¯å‘é‡ + ç¼©æ”¾\n",
    "        token_embeddings = self.tok_emb(x) * self.scale\n",
    "\n",
    "        # step 2: è·å–ä½ç½®ç¼–ç \n",
    "        position_embeddings = self.pos_emb(x)\n",
    "\n",
    "        # step 3: ç›¸åŠ  (å¹¿æ’­æœºåˆ¶: [batch, len, dim] + [len, dim])\n",
    "        input_embeddings = token_embeddings + position_embeddings\n",
    "\n",
    "        # step 4: Dropout\n",
    "        return self.drop_out(input_embeddings)"
   ],
   "id": "4eadf9d5105ed068",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T08:44:29.099629Z",
     "start_time": "2026-01-16T08:44:29.080917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#éªŒè¯ç¼–ç æ˜¯å¦æ­£ç¡®\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def verify_transformer_embedding_noplot():\n",
    "    print(\"å¼€å§‹éªŒè¯ Transformer Embedding æ¨¡å—...\")\n",
    "\n",
    "    # ==========================\n",
    "    # 1. åŸºç¡€å‚æ•°è®¾ç½®\n",
    "    # ==========================\n",
    "    vocab_size = 1000\n",
    "    d_model = 512\n",
    "    max_len = 100\n",
    "    drop_prob = 0.1\n",
    "    padding_idx = 0\n",
    "\n",
    "    # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"   è®¾å¤‡: {device}\")\n",
    "\n",
    "    try:\n",
    "        # ==========================\n",
    "        # 2. å®ä¾‹åŒ–æ¨¡å‹\n",
    "        # ==========================\n",
    "        # å‡è®¾ TransformerEmbedding ç±»å·²ç»å®šä¹‰åœ¨ä¸Šä¸‹æ–‡ä¸­\n",
    "        model = TransformerEmbedding(\n",
    "            vocab_size=vocab_size,\n",
    "            d_model=d_model,\n",
    "            max_len=max_len,\n",
    "            drop_prob=drop_prob,\n",
    "            device=device,\n",
    "            padding_idx=padding_idx\n",
    "        ).to(device)\n",
    "        print(\"    æ¨¡å‹å®ä¾‹åŒ–æˆåŠŸ\")\n",
    "\n",
    "        # ==========================\n",
    "        # 3. ç»´åº¦å½¢çŠ¶æ£€æŸ¥ (Shape Check)\n",
    "        # ==========================\n",
    "        batch_size = 2\n",
    "        seq_len = 50\n",
    "        # æ„é€ è¾“å…¥ï¼ŒåŒ…å«ä¸€äº› 0 (padding)\n",
    "        input_data = torch.randint(1, vocab_size, (batch_size, seq_len)).to(device)\n",
    "        input_data[:, -5:] = padding_idx # æœ€å5ä¸ªè®¾ä¸º pad\n",
    "\n",
    "        # å‰å‘ä¼ æ’­\n",
    "        output = model(input_data)\n",
    "\n",
    "        expected_shape = (batch_size, seq_len, d_model)\n",
    "        if output.shape == expected_shape:\n",
    "            print(f\"    è¾“å‡ºç»´åº¦æ£€æŸ¥é€šè¿‡: {output.shape}\")\n",
    "        else:\n",
    "            print(f\"    è¾“å‡ºç»´åº¦é”™è¯¯: æœŸæœ› {expected_shape}, å®é™… {output.shape}\")\n",
    "            return\n",
    "\n",
    "        # ==========================\n",
    "        # 4. Padding é€»è¾‘æ£€æŸ¥\n",
    "        # ==========================\n",
    "        # æ£€æŸ¥ TokenEmbedding å±‚çš„æƒé‡ï¼Œpadding_idx å¯¹åº”çš„è¡Œåº”è¯¥æ˜¯å…¨ 0\n",
    "        emb_weight = model.tok_emb.weight.data.cpu()\n",
    "        if torch.equal(emb_weight[padding_idx], torch.zeros(d_model)):\n",
    "            print(\"    Padding Index é€»è¾‘é€šè¿‡: Token Embedding ä¸­ Pad å¯¹åº”çš„å‘é‡å…¨ä¸º 0\")\n",
    "        else:\n",
    "            print(\"    Padding Index é€»è¾‘å¤±è´¥: Pad å‘é‡ä¸ä¸º 0ï¼Œè¯·æ£€æŸ¥ padding_idx æ˜¯å¦ä¼ å…¥ super().__init__\")\n",
    "\n",
    "        print(\"ğŸ‰ éªŒè¯å…¨éƒ¨å®Œæˆï¼Embedding æ¨¡å—é€»è¾‘æ­£å¸¸ã€‚\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# è¿è¡ŒéªŒè¯\n",
    "verify_transformer_embedding_noplot()"
   ],
   "id": "89209a9429394bea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹éªŒè¯ Transformer Embedding æ¨¡å—...\n",
      "   è®¾å¤‡: cuda\n",
      "    æ¨¡å‹å®ä¾‹åŒ–æˆåŠŸ\n",
      "    è¾“å‡ºç»´åº¦æ£€æŸ¥é€šè¿‡: torch.Size([2, 50, 512])\n",
      "    Padding Index é€»è¾‘é€šè¿‡: Token Embedding ä¸­ Pad å¯¹åº”çš„å‘é‡å…¨ä¸º 0\n",
      "ğŸ‰ éªŒè¯å…¨éƒ¨å®Œæˆï¼Embedding æ¨¡å—é€»è¾‘æ­£å¸¸ã€‚\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "######  2.2 Mask æ©ç æœºåˆ¶ (è‡³å…³é‡è¦)\n",
   "id": "1f18180b739e90f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T08:52:50.553231Z",
     "start_time": "2026-01-16T08:52:50.537536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    å¤šå¤´æ³¨æ„åŠ›çš„ç›®çš„æ˜¯è®©æ¨¡å‹å¯ä»¥ä»ä¸åŒçš„å­ç©ºé—´ï¼ˆdifferent subspacesï¼‰å­¦ä¹ ä¿¡æ¯ã€‚\n",
    "    æ¯”å¦‚ï¼šä¸€ä¸ªå¤´å…³æ³¨è¯­æ³•å…³ç³»ï¼Œå¦ä¸€ä¸ªå¤´å…³æ³¨è¯­ä¹‰æŒ‡ä»£ã€‚\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, n_head):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.d_head = d_model // n_head # æ¯ä¸ªå¤´çš„ç»´åº¦ (512 / 8 = 64)\n",
    "\n",
    "        # [Standard] å¼ºåˆ¶æ£€æŸ¥ d_model æ˜¯å¦èƒ½è¢« n_head æ•´é™¤\n",
    "        assert d_model % n_head == 0, f\"d_model ({d_model}) must be divisible by n_head ({n_head})\"\n",
    "\n",
    "        # å®šä¹‰ W_q, W_k, W_v çŸ©é˜µ (ä½¿ç”¨å…¨è¿æ¥å±‚å®ç°)\n",
    "        # è¿™é‡Œçš„è¾“å…¥è¾“å‡ºéƒ½æ˜¯ d_modelï¼Œå…·ä½“çš„â€œåˆ†å¤´â€é€»è¾‘åœ¨ forward é‡Œåš\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # å®šä¹‰æœ€åè¾“å‡ºçš„çº¿æ€§å±‚ W_o\n",
    "        self.fc_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        \"\"\"\n",
    "        q, k, v: [batch_size, seq_len, d_model]\n",
    "        mask:    [batch_size, 1, 1, seq_len] (æˆ–ç±»ä¼¼å¹¿æ’­ç»´åº¦)\n",
    "        \"\"\"\n",
    "        batch_size = q.size(0)\n",
    "\n",
    "        # =================================================\n",
    "        # 1. çº¿æ€§å˜æ¢ + åˆ†å¤´ (Split Heads)\n",
    "        # =================================================\n",
    "        # åŸå§‹: [batch, len, d_model]\n",
    "        # å˜æ¢: [batch, len, n_head, d_head]\n",
    "        # è½¬ç½®: [batch, n_head, len, d_head] -> è¿™ä¸€æ­¥æ˜¯ä¸ºäº†è®© n_head ç»´åº¦åœ¨å‰é¢ï¼Œæ–¹ä¾¿å¹¶è¡Œè®¡ç®—\n",
    "        Q = self.w_q(q).view(batch_size, -1, self.n_head, self.d_head).transpose(1, 2)\n",
    "        K = self.w_k(k).view(batch_size, -1, self.n_head, self.d_head).transpose(1, 2)\n",
    "        V = self.w_v(v).view(batch_size, -1, self.n_head, self.d_head).transpose(1, 2)\n",
    "\n",
    "        # =================================================\n",
    "        # 2. ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ› (Scaled Dot-Product Attention)\n",
    "        # =================================================\n",
    "        # 2.1 è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° scores = Q * K^T / sqrt(d_k)\n",
    "        # MatMul: [batch, head, len_q, d] x [batch, head, d, len_k] -> [batch, head, len_q, len_k]\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_head)\n",
    "\n",
    "        # 2.2 åº”ç”¨ Mask (æ ¸å¿ƒé€»è¾‘)\n",
    "        if mask is not None:\n",
    "            # [User Comment] mask ä¸º 0 çš„ä½ç½®æ›¿æ¢ä¸ºæå°å€¼ (-1e9)\n",
    "            # è¿™æ · Softmax åè¿™äº›ä½ç½®çš„æ¦‚ç‡è¶‹è¿‘äº 0ï¼Œæ¨¡å‹å°±ä¸ä¼šå…³æ³¨å®ƒä»¬\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        # 2.3 Softmax å½’ä¸€åŒ– (å¾—åˆ°æ³¨æ„åŠ›æƒé‡)\n",
    "        attn_weights = torch.softmax(scores, dim=-1)\n",
    "\n",
    "        # 2.4 åŠ æƒæ±‚å’Œ: weights * V\n",
    "        # [batch, head, len_q, len_k] x [batch, head, len_k, d_head] -> [batch, head, len_q, d_head]\n",
    "        context = torch.matmul(attn_weights, V)\n",
    "\n",
    "        # =================================================\n",
    "        # 3. æ‹¼æ¥å¤šå¤´ (Concat Heads)\n",
    "        # =================================================\n",
    "        # [batch, head, len, d_head] -> [batch, len, head, d_head] -> [batch, len, d_model]\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "\n",
    "        # =================================================\n",
    "        # 4. æœ€ç»ˆçº¿æ€§è¾“å‡º (Final Linear)\n",
    "        # =================================================\n",
    "        output = self.fc_out(context)\n",
    "\n",
    "        return output, attn_weights"
   ],
   "id": "6a0e9ab07c1f7ff0",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T08:53:01.346408Z",
     "start_time": "2026-01-16T08:53:01.195125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- éªŒè¯ 2.2 Attention æ¨¡å— ---\n",
    "print(\"\\n-------- æµ‹è¯• 2.2 Multi-Head Attention --------\")\n",
    "\n",
    "# 1. æ¨¡æ‹Ÿå‚æ•°\n",
    "d_model = 512\n",
    "n_head = 8\n",
    "batch_size = 2\n",
    "seq_len = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. å®ä¾‹åŒ–\n",
    "mha = MultiHeadAttention(d_model=d_model, n_head=n_head).to(device)\n",
    "\n",
    "# 3. æ¨¡æ‹Ÿè¾“å…¥ (å‡è®¾ Q, K, V éƒ½æ˜¯åŒä¸€ä¸ªè¾“å…¥ï¼Œå³ Self-Attention)\n",
    "x = torch.randn(batch_size, seq_len, d_model).to(device)\n",
    "\n",
    "# 4. æ¨¡æ‹Ÿ Mask (batch=2, 1, 1, len=10)\n",
    "# å‡è®¾æœ€åä¸¤ä¸ªè¯æ˜¯ padding (0)\n",
    "mask = torch.ones(batch_size, 1, 1, seq_len).to(device)\n",
    "mask[:, :, :, -2:] = 0 # è®¾ä¸ºé®æŒ¡\n",
    "\n",
    "# 5. å‰å‘ä¼ æ’­\n",
    "output, weights = mha(x, x, x, mask=mask)\n",
    "\n",
    "print(f\"è¾“å…¥å½¢çŠ¶: {x.shape}\")        # [2, 10, 512]\n",
    "print(f\"è¾“å‡ºå½¢çŠ¶: {output.shape}\")   # [2, 10, 512] (åº”ä¸è¾“å…¥ä¸€è‡´)\n",
    "print(f\"æƒé‡å½¢çŠ¶: {weights.shape}\")  # [2, 8, 10, 10] (Batch, Head, Q_Len, K_Len)\n",
    "\n",
    "if output.shape == (batch_size, seq_len, d_model):\n",
    "    print(\" Attention æ¨¡å—ç»´åº¦éªŒè¯é€šè¿‡ï¼\")"
   ],
   "id": "bee0bd5d38ca8292",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------- æµ‹è¯• 2.2 Multi-Head Attention --------\n",
      "è¾“å…¥å½¢çŠ¶: torch.Size([2, 10, 512])\n",
      "è¾“å‡ºå½¢çŠ¶: torch.Size([2, 10, 512])\n",
      "æƒé‡å½¢çŠ¶: torch.Size([2, 8, 10, 10])\n",
      " Attention æ¨¡å—ç»´åº¦éªŒè¯é€šè¿‡ï¼\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### 2.3 å‰é¦ˆç¥ç»ç½‘ç»œ (Feed-Forward)ï¼šç»™æ¨¡å‹å¢åŠ éçº¿æ€§å˜æ¢èƒ½åŠ›ã€‚",
   "id": "c949bc6efce24870"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===================================================================\n",
    "# 2.3 Position-wise Feed-Forward Network (å‰é¦ˆç¥ç»ç½‘ç»œ)\n",
    "# ===================================================================\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"\"\"\n",
    "    è¿™æ˜¯ä¸€ä¸ªä¸¤å±‚çš„å…¨è¿æ¥ç½‘ç»œï¼Œä¸­é—´åŒ…å« ReLU æ¿€æ´»å‡½æ•°ã€‚\n",
    "    å®ƒå¯¹åºåˆ—ä¸­çš„æ¯ä¸€ä¸ªä½ç½® (position) ç‹¬ç«‹ä¸”ç›¸åŒåœ°è¿›è¡Œå¤„ç†ã€‚\n",
    "    å…¬å¼: FFN(x) = max(0, xW1 + b1)W2 + b2\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, ffn_hidden, drop_prob=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        # d_model: è¾“å…¥/è¾“å‡ºç»´åº¦ (512)\n",
    "        # ffn_hidden: éšè—å±‚ç»´åº¦ (2048) - é€šå¸¸æ˜¯ d_model çš„ 4 å€\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, ffn_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_prob),\n",
    "            nn.Linear(ffn_hidden, d_model)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_len, d_model]\n",
    "        return self.net(x)"
   ],
   "id": "48cf173c98e0a3ae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
